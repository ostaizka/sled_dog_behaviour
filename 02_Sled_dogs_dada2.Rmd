---
title: "dada2"
output: html_document
date: "2024-04-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libraries, echo=FALSE}
library(dada2)
```

```{r}
setwd("/Pool1")
samples <- scan("samples", what="character")
codeDADA1="P1"
projectdir="/Users/Projects/GreenDogs/DADA2/Seq1/"
```

## Filtering
```{r}
forward_reads <- paste0(samples, "_1_trimmed.fq")
reverse_reads <- paste0(samples, "_2_trimmed.fq")
filtered_forward_reads <- paste0(samples, "_1_filtered.fq")
filtered_reverse_reads <- paste0(samples, "_2_filtered.fq")

filtered_out <- filterAndTrim(forward_reads, filtered_forward_reads, reverse_reads, filtered_reverse_reads, maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, truncLen=c(240,220), compress=TRUE, multithread=TRUE)
```

### Some input samples had no read that pass the filter
```{bash}
terminal: ls *_1_filtered.fq | sed "s/_1_filtered\.fq//g" > samples_fil
```
```{r}
samples_fil <- scan("samples_fil", what="character")
filtered_forward_reads <- paste0(samples_fil, "_1_filtered.fq")
filtered_reverse_reads <- paste0(samples_fil, "_2_filtered.fq")
```

## Generating an error model of our data by learning the specific error-signature of our dataset
```{r}
err_forward_reads <- learnErrors(filtered_forward_reads, multithread=TRUE)
err_reverse_reads <- learnErrors(filtered_reverse_reads, multithread=TRUE)
```

## Dereplication
```{r}
derep_forward <- derepFastq(filtered_forward_reads, verbose=TRUE)
names(derep_forward) <- samples_fil
derep_reverse <- derepFastq(filtered_reverse_reads, verbose=TRUE)
names(derep_reverse) <- samples_fil
saveRDS(derep_forward, paste(projectdir,"derep_forward_",codeDADA1,".RData",sep=""))
saveRDS(derep_reverse, paste(projectdir,"derep_reverse_",codeDADA1,".RData",sep=""))
```

## Inferring ASVs
```{r}
dada_forward <- dada(derep_forward, err=err_forward_reads, multithread=TRUE)
dada_reverse <- dada(derep_reverse, err=err_reverse_reads, multithread=TRUE)
```

## Merging forward and reverse reads ####

```{r}
merged_amplicons_default <- mergePairs(dada_forward, derep_forward, dada_reverse,
                                       derep_reverse, verbose=TRUE)
saveRDS(merged_amplicons_default,paste(projectdir,"merged_amplicons_default",codeDADA1,".RData",sep=""))
```

## Construct sequence table and remove chimeras
```{r}
seqtab_default <- makeSequenceTable(merged_amplicons_default)
saveRDS(seqtab_default,paste(projectdir,"seqtab_default_",codeDADA1,".rds",sep=""))
```

# Pool1 reverse

```{r}
codeDADA1Rev="P1_rev"

forward_reads_rev1 <- paste0(samples, "_1rev_trimmed.fq")
reverse_reads_rev1 <- paste0(samples, "_2rev_trimmed.fq")
filtered_forward_reads_rev1 <- paste0(samples, "_1rev_filtered.fq")
filtered_reverse_reads_rev1 <- paste0(samples, "_2rev_filtered.fq")
#plotQualityProfile(filtered_forward_reads_rev1[1:4])
#plotQualityProfile(filtered_reverse_reads_rev1[1:4])
```

## Filtering
```{r}
filtered_out_rev1 <- filterAndTrim(forward_reads_rev1, filtered_forward_reads_rev1, reverse_reads_rev1, filtered_reverse_reads_rev1, maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, truncLen=c(220,240), compress=TRUE, multithread=TRUE)
```
```{bash}
# some input samples had no read that pass the filter
ls *_1rev_filtered.fq | sed "s/_1rev_filtered\.fq//g" > samples1_fil
```
```{r}
samples1_fil <- scan("samples1_fil", what="character")
filtered_forward_reads_rev1 <- paste0(samples1_fil, "_1rev_filtered.fq")
filtered_reverse_reads_rev1 <- paste0(samples1_fil, "_2rev_filtered.fq")
```

## Generating an error model of our data by learning the specific error-signature of our dataset
```{r}
err_forward_reads_rev1 <- learnErrors(filtered_forward_reads_rev1, multithread=TRUE)
err_reverse_reads_rev1 <- learnErrors(filtered_reverse_reads_rev1, multithread=TRUE)
```

## Dereplication
```{r}
derep_forward_rev1 <- derepFastq(filtered_forward_reads_rev1, verbose=TRUE)
names(derep_forward_rev1) <- samples1_fil
derep_reverse_rev1 <- derepFastq(filtered_reverse_reads_rev1, verbose=TRUE)
names(derep_reverse_rev1) <- samples1_fil
saveRDS(derep_forward_rev1, paste(projectdir,"derep_forward_",codeDADA1Rev,".RData",sep=""))
saveRDS(derep_reverse_rev1, paste(projectdir,"derep_reverse_",codeDADA1Rev,".RData",sep=""))

```

## Inferring ASVs
```{r}
dada_forward_rev1 <- dada(derep_forward_rev1, err=err_forward_reads_rev1, multithread=TRUE)
dada_reverse_rev1 <- dada(derep_reverse_rev1, err=err_reverse_reads_rev1, multithread=TRUE)
```

## Merging forward and reverse reads ####
```{r}
merged_amplicons_default_rev1 <- mergePairs(dada_forward_rev1, derep_forward_rev1, dada_reverse_rev1,
                                            derep_reverse_rev1, verbose=TRUE)
saveRDS(merged_amplicons_default_rev1, paste(projectdir,"merged_amplicons_default_",codeDADA1Rev,".RData",sep=""))
```

## Construct sequence table and remove chimeras
```{r}
seqtab_default_rev1 <- makeSequenceTable(merged_amplicons_default_rev1)
saveRDS(seqtab_default_rev1, paste(projectdir,"seqtab_default_",codeDADA1Rev,".rds",sep="")) 
```

# Pool2
```{r}
setwd("/Pool2")
codeDADA2="P2"
samples2 <- scan("samples2", what="character")

# one holding the file names of all the forward reads (only one direction)
forward_reads2 <- paste0(samples2, "_1_trimmed.fq")
# and one with the reverse
reverse_reads2 <- paste0(samples2, "_2_trimmed.fq")
# and variables holding file names for the forward and reverse
filtered_forward_reads2 <- paste0(samples2, "_1_filtered.fq")
filtered_reverse_reads2 <- paste0(samples2, "_2_filtered.fq")
```

```{r}
filtered_out2 <- filterAndTrim(forward_reads2, filtered_forward_reads2, reverse_reads2, filtered_reverse_reads2, maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, truncLen=c(240,220), compress=TRUE, multithread=TRUE)
```

```{bash}
#when some input samples had no read that pass the filter
ls *_1_filtered.fq | sed "s/_1_filtered\.fq//g" > samples2_fil
```

```{r}
samples2_fil <- scan("samples2_fil", what="character")
filtered_forward_reads2 <- paste0(samples2_fil, "_1_filtered.fq")
filtered_reverse_reads2 <- paste0(samples2_fil, "_2_filtered.fq")
```

## Generating an error model
```{r}
err_forward_reads2 <- learnErrors(filtered_forward_reads2, multithread=TRUE)
err_reverse_reads2 <- learnErrors(filtered_reverse_reads2, multithread=TRUE)
```

## Dereplication
```{r}
derep_forward2 <- derepFastq(filtered_forward_reads2, verbose=TRUE)
names(derep_forward2) <- samples2
derep_reverse2 <- derepFastq(filtered_reverse_reads2, verbose=TRUE)
names(derep_reverse2) <- samples2
saveRDS(derep_forward2, paste(projectdir,"derep_forward_",codeDADA2,".RData",sep=""))
saveRDS(derep_reverse2, paste(projectdir,"derep_reverse_",codeDADA2,".RData",sep=""))
```

## Inferring ASVs
```{r}
dada_reverse2 <- dada(derep_reverse2, err=err_reverse_reads2, multithread=TRUE)
dada_forward2 <- dada(derep_forward2, err=err_forward_reads2, multithread=TRUE)
```

## Merging forward and reverse reads
```{r}
merged_amplicons2_default <- mergePairs(dada_forward2, derep_forward2, dada_reverse2,
                                        derep_reverse2, verbose=TRUE)
saveRDS(merged_amplicons2_default, paste(projectdir,"merged_amplicons_default",codeDADA2,".RData",sep=""))
```

## Construct sequence table and remove chimeras
```{r}
seqtab2_default <- makeSequenceTable(merged_amplicons2_default)
saveRDS(seqtab2_default, paste(projectdir,"seqtab_default_",codeDADA2,".rds",sep=""))
```

# Pool2 reverse

```{r}
codeDADA2Rev="P2_rev"
forward_reads2_rev1 <- paste0(samples2, "_1rev_trimmed.fq")
reverse_reads2_rev1 <- paste0(samples2, "_2rev_trimmed.fq")
filtered_forward_reads2_rev1 <- paste0(samples2, "_1rev_filtered.fq")
filtered_reverse_reads2_rev1 <- paste0(samples2, "_2rev_filtered.fq")
#plotQualityProfile(filtered_reverse_reads[1:4])
#plotQualityProfile(filtered_forward_reads[1:4])
```

```{r}
filtered_out2_rev1 <- filterAndTrim(forward_reads2_rev1, filtered_forward_reads2_rev1, reverse_reads2_rev1, filtered_reverse_reads2_rev1, maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, truncLen=c(220,240), compress=TRUE, multithread=TRUE)
```
```{bash}
# some input samples had no read that pass the filter
ls *_1rev_filtered.fq | sed "s/_1rev_filtered\.fq//g" > samples2_filt_rev
```

```{r}
samples2_filt_rev <- scan("samples2_filt_rev", what="character")
filtered_forward_reads2_rev1 <- paste0(samples2_filt_rev, "_1rev_filtered.fq")
filtered_reverse_reads2_rev1 <- paste0(samples2_filt_rev, "_2rev_filtered.fq")
```

## Generating an error model

```{r}
err_forward_reads2_rev1 <- learnErrors(filtered_forward_reads2_rev1, multithread=TRUE)
err_reverse_reads2_rev1 <- learnErrors(filtered_reverse_reads2_rev1, multithread=TRUE)
```

## Dereplication
```{r}
derep_forward2_rev1 <- derepFastq(filtered_forward_reads2_rev1, verbose=TRUE)
names(derep_forward2_rev1) <- samples2
derep_reverse2_rev1 <- derepFastq(filtered_reverse_reads2_rev1, verbose=TRUE)
names(derep_reverse2_rev1) <- samples2
saveRDS(derep_forward2_rev1, paste(projectdir,"derep_forward_",codeDADA2Rev,".RData",sep=""))
saveRDS(derep_reverse2_rev1, paste(projectdir,"derep_reverse_",codeDADA2Rev,".RData",sep=""))
```

## Inferring ASVs
```{r}
dada_forward2_rev1 <- dada(derep_forward2_rev1, err=err_forward_reads2_rev1, multithread=TRUE)
dada_reverse2_rev1 <- dada(derep_reverse2_rev1, err=err_reverse_reads2_rev1, multithread=TRUE)
```

## Merging forward and reverse reads
```{r}
merged_amplicons2_default_rev1 <- mergePairs(dada_forward2_rev1, derep_forward2_rev1, dada_reverse2_rev1,
                                             derep_reverse2_rev1, verbose=TRUE)
saveRDS(merged_amplicons2_default_rev1, paste(projectdir,"merged_amplicons_default_",codeDADA2Rev,".RData",sep=""))
```

## Construct sequence table and remove chimeras
```{r}
seqtab_default2_rev1 <- makeSequenceTable(merged_amplicons2_default_rev1)
saveRDS(seqtab_default2_rev1, paste(projectdir,"seqtab_default_",codeDADA2Rev,".rds",sep=""))
```

# Merge multiple runs (when we have different runs)
```{r}
st1 <- readRDS(paste(projectdir,"seqtab_default_",codeDADA1,".rds",sep=""))
st2 <- readRDS(paste(projectdir,"seqtab_default_",codeDADA1Rev,".rds",sep=""))
st3 <- readRDS(paste(projectdir,"seqtab_default_",codeDADA2,".rds",sep=""))
st4 <- readRDS(paste(projectdir,"seqtab_default_",codeDADA2Rev,".rds",sep=""))
rownames(st2) <- paste0(rownames(st2),"_rev")
rownames(st4) <- paste0(rownames(st4),"_rev")
st.all <- mergeSequenceTables(st1, st2, st3, st4)
```

# Chimera identification
```{r}
seqtab.nochim <- removeBimeraDenovo(st.all, multithread=TRUE, verbose=TRUE)
saveRDS(seqtab.nochim,paste(projectdir,"seqtab.nochim_",codeGeneral,".RData",sep=""))
```

# Assigning taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "/Users/ostaizkaaizpurua/Documents/Silva_DADA2/silva_nr_v138_train_set.fa.gz", tryRC=T)
saveRDS(taxa, paste(projectdir,"taxa_",codeGeneral,".RData",sep=""))
```

# Summary
```{r}
getN <- function(x) sum(getUniques(x))

summary_tab <- data.frame(row.names=samples, dada2_input=filtered_out[,1],
                          filtered=filtered_out[,2], dada_f=sapply(dada_forward, getN),
                          dada_r=sapply(dada_reverse, getN), merged=sapply(merged_amplicons_default, getN),
                          nonchim=rowSums(seqtab.nochim),
                          final_perc_reads_retained=round(rowSums(seqtab.nochim)/filtered_out[,1]*100, 1))
summary_tab
```

# Phylogenetic tree
```{r}
library(DECIPHER)
library(phangorn)
seqs <- getSequences(seqtab.nochim)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phangAlign)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
                    rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
```

# Extracting the standard goods from DADA2

```{r}
asv_seqs <- colnames(seqtab.nochim)
asv_headers <- vector(dim(seqtab.nochim)[2], mode="character")

for (i in 1:dim(seqtab.nochim)[2]) {
  asv_headers[i] <- paste(">ASV", i, sep="_")
}

projectdir="/DADA2/"
asv_fasta <- c(rbind(asv_headers, asv_seqs))
write(asv_fasta, paste(projectdir,"Results/Tables/ASVs_",codeGeneral,".fa",sep=""))

#count table:
asv_tab <- t(seqtab.nochim)
row.names(asv_tab) <- sub(">", "", asv_headers)
write.table(asv_tab, paste(projectdir,"Results/Tables/ASVs_counts_",codeGeneral,".tsv",sep=""), sep="\t", quote=F, col.names=NA)

asv_tab1 <- t(seqtab.nochim)
write.table(asv_tab1, paste(projectdir,"Results/Tables/ASVs_counts_names_",codeGeneral,".tsv",sep=""), sep="\t", quote=F, col.names=NA)

#tax table:
asv_tax <- taxa
row.names(asv_tax) <- sub(">", "", asv_headers)
write.table(asv_tax, paste(projectdir,"Results/Tables/ASVs_taxonomy_",codeGeneral,".tsv",sep=""), sep="\t", quote=F, col.names=NA)
```

# save the working environment
```{r}
save.image(paste(projectdir,"DADA2/all_Dada_final",codeGeneral,".RData",sep=""))
```

# Create a phyloseq object
```{r}
library(phyloseq)
asv_tab1 <- t(seqtab.nochim)
asv_tab1_table <- as.data.frame(asv_tab1)
#change the name and merge samples with same name
names(asv_tab1_table) = gsub(pattern = "_rev", replacement = "", x = names(asv_tab1_table)) 
merge_asv_tab1 <- t(rowsum(t(asv_tab1_table), group = colnames(asv_tab1_table), na.rm = T))
count_phy <- otu_table(merge_asv_tab1, taxa_are_rows=T)
count_phy1 <- otu_table(merge_asv_tab1, taxa_are_rows=F)
#make the object
ps1 <- phyloseq(count_phy,tax_table(taxa),phy_tree(fitGTR$tree))
```

# Add metadata info
```{r}
metadata <- read.table(paste(projectdirGD,"meta_dog.csv",sep=""),header=TRUE,sep=";",row.names=1)
hierarchy_all <- tibble::rownames_to_column(metadata, "Samples")
sample_tab <- sample_data(metadata1)
ps1_all=merge_phyloseq(ps1, sample_tab)
saveRDS(ps1_all,"/DADA2/Seq1/physeq_Phylum_contaminants.RData")
```

